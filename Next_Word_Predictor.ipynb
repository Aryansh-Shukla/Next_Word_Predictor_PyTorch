{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7shJ7NZ3b52",
        "outputId": "364a0c5c-52b3-4e7f-cb97-1a27824ddcc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "VRqjPap03fTu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish\n",
        "How will I be informed about the upcoming class?\n",
        "You will get a mail from our side before every paid session once you become a paid user.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "You can mail us at nitish.campusx@gmail.com\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "Can we pay the entire amount of Rs 5600 all at once?\n",
        "Unfortunately no, the program follows a monthly subscription model.\n",
        "What is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n",
        "15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\n",
        "What if I don’t like the course after making the payment. What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
        "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
        "Why lifetime validity is not provided?\n",
        "Because of the low course fee.\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 5600\n",
        "You have to attempt all the course assessments.\n",
        "I am joining late. How can I pay payment of the earlier months?\n",
        "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
        "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
        "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "svrSdq724GXN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-3UVqcBG4DF",
        "outputId": "327eba1f-dc52-469f-a718-4b9b3d51a3e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "UbuRN6kGHHyA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {'<unk>':0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGuu65NqHSIK",
        "outputId": "e5d5a37c-c16f-405d-b7b8-09928a816131"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'about': 1,\n",
              " 'the': 2,\n",
              " 'program': 3,\n",
              " 'what': 4,\n",
              " 'is': 5,\n",
              " 'course': 6,\n",
              " 'fee': 7,\n",
              " 'for': 8,\n",
              " 'data': 9,\n",
              " 'science': 10,\n",
              " 'mentorship': 11,\n",
              " '(': 12,\n",
              " 'dsmp': 13,\n",
              " '2023': 14,\n",
              " ')': 15,\n",
              " 'follows': 16,\n",
              " 'a': 17,\n",
              " 'monthly': 18,\n",
              " 'subscription': 19,\n",
              " 'model': 20,\n",
              " 'where': 21,\n",
              " 'you': 22,\n",
              " 'have': 23,\n",
              " 'to': 24,\n",
              " 'make': 25,\n",
              " 'payments': 26,\n",
              " 'of': 27,\n",
              " 'rs': 28,\n",
              " '799/month': 29,\n",
              " '.': 30,\n",
              " 'total': 31,\n",
              " 'duration': 32,\n",
              " '?': 33,\n",
              " '7': 34,\n",
              " 'months': 35,\n",
              " 'so': 36,\n",
              " 'becomes': 37,\n",
              " '799': 38,\n",
              " '*': 39,\n",
              " '=': 40,\n",
              " '5600': 41,\n",
              " 'approx': 42,\n",
              " 'syllabus': 43,\n",
              " 'we': 44,\n",
              " 'will': 45,\n",
              " 'be': 46,\n",
              " 'covering': 47,\n",
              " 'following': 48,\n",
              " 'modules': 49,\n",
              " ':': 50,\n",
              " 'python': 51,\n",
              " 'fundamentals': 52,\n",
              " 'libraries': 53,\n",
              " 'analysis': 54,\n",
              " 'sql': 55,\n",
              " 'maths': 56,\n",
              " 'machine': 57,\n",
              " 'learning': 58,\n",
              " 'ml': 59,\n",
              " 'algorithms': 60,\n",
              " 'practical': 61,\n",
              " 'mlops': 62,\n",
              " 'case': 63,\n",
              " 'studies': 64,\n",
              " 'can': 65,\n",
              " 'check': 66,\n",
              " 'detailed': 67,\n",
              " 'here': 68,\n",
              " '-': 69,\n",
              " 'https': 70,\n",
              " '//learnwith.campusx.in/courses/campusx-data-science-mentorship-program-637339afe4b0615a1bbed390': 71,\n",
              " 'deep': 72,\n",
              " 'and': 73,\n",
              " 'nlp': 74,\n",
              " 'part': 75,\n",
              " 'this': 76,\n",
              " 'no': 77,\n",
              " ',': 78,\n",
              " 'both': 79,\n",
              " 'are': 80,\n",
              " 'not': 81,\n",
              " '’': 82,\n",
              " 's': 83,\n",
              " 'curriculum': 84,\n",
              " 'if': 85,\n",
              " 'i': 86,\n",
              " 'miss': 87,\n",
              " 'live': 88,\n",
              " 'session': 89,\n",
              " 'get': 90,\n",
              " 'recording': 91,\n",
              " 'yes': 92,\n",
              " 'all': 93,\n",
              " 'our': 94,\n",
              " 'sessions': 95,\n",
              " 'recorded': 96,\n",
              " 'even': 97,\n",
              " 'go': 98,\n",
              " 'back': 99,\n",
              " 'watch': 100,\n",
              " 'find': 101,\n",
              " 'class': 102,\n",
              " 'schedule': 103,\n",
              " 'checkout': 104,\n",
              " 'google': 105,\n",
              " 'sheet': 106,\n",
              " 'see': 107,\n",
              " 'month': 108,\n",
              " 'by': 109,\n",
              " 'time': 110,\n",
              " 'table': 111,\n",
              " '//docs.google.com/spreadsheets/d/16ootax_a6oraecg4emgexhqqpv3noqpyku7rj6arozk/edit': 112,\n",
              " 'usp=sharing': 113,\n",
              " 'roughly': 114,\n",
              " 'last': 115,\n",
              " '2': 116,\n",
              " 'hours': 117,\n",
              " 'language': 118,\n",
              " 'spoken': 119,\n",
              " 'instructor': 120,\n",
              " 'during': 121,\n",
              " 'hinglish': 122,\n",
              " 'how': 123,\n",
              " 'informed': 124,\n",
              " 'upcoming': 125,\n",
              " 'mail': 126,\n",
              " 'from': 127,\n",
              " 'side': 128,\n",
              " 'before': 129,\n",
              " 'every': 130,\n",
              " 'paid': 131,\n",
              " 'once': 132,\n",
              " 'become': 133,\n",
              " 'user': 134,\n",
              " 'do': 135,\n",
              " 'am': 136,\n",
              " 'non-tech': 137,\n",
              " 'background': 138,\n",
              " 'absolutely': 139,\n",
              " 'late': 140,\n",
              " 'join': 141,\n",
              " 'in': 142,\n",
              " 'middle': 143,\n",
              " 'anytime': 144,\n",
              " 'join/pay': 145,\n",
              " 'able': 146,\n",
              " 'past': 147,\n",
              " 'lectures': 148,\n",
              " 'payment': 149,\n",
              " 'content': 150,\n",
              " 'your': 151,\n",
              " 'dashboard': 152,\n",
              " 'submit': 153,\n",
              " 'task': 154,\n",
              " 'don': 155,\n",
              " 't': 156,\n",
              " 'provide': 157,\n",
              " 'with': 158,\n",
              " 'solutions': 159,\n",
              " 'self': 160,\n",
              " 'evaluate': 161,\n",
              " 'yourself': 162,\n",
              " 'contact': 163,\n",
              " 'us': 164,\n",
              " 'at': 165,\n",
              " 'nitish.campusx': 166,\n",
              " '@': 167,\n",
              " 'gmail.com': 168,\n",
              " 'payment/registration': 169,\n",
              " 'related': 170,\n",
              " 'questions': 171,\n",
              " 'youtube': 172,\n",
              " 'channel': 173,\n",
              " 'or': 174,\n",
              " 'website': 175,\n",
              " 'on': 176,\n",
              " 'link': 177,\n",
              " '//learnwith.campusx.in/': 178,\n",
              " 'pay': 179,\n",
              " 'entire': 180,\n",
              " 'amount': 181,\n",
              " 'unfortunately': 182,\n",
              " 'validity': 183,\n",
              " 'suppose': 184,\n",
              " '15th': 185,\n",
              " 'jan': 186,\n",
              " 'then': 187,\n",
              " 'again': 188,\n",
              " '1st': 189,\n",
              " 'feb': 190,\n",
              " 'feb.': 191,\n",
              " 'period': 192,\n",
              " '30': 193,\n",
              " 'days': 194,\n",
              " 'day': 195,\n",
              " 'essentially': 196,\n",
              " 'wait': 197,\n",
              " 'end': 198,\n",
              " 'like': 199,\n",
              " 'after': 200,\n",
              " 'making': 201,\n",
              " 'refund': 202,\n",
              " 'policy': 203,\n",
              " 'made': 204,\n",
              " 'living': 205,\n",
              " 'outside': 206,\n",
              " 'india': 207,\n",
              " 'should': 208,\n",
              " 'sending': 209,\n",
              " 'post': 210,\n",
              " 'registration': 211,\n",
              " 'queries': 212,\n",
              " 'till': 213,\n",
              " 'when': 214,\n",
              " 'view': 215,\n",
              " 'videos': 216,\n",
              " 'one': 217,\n",
              " 'tricky': 218,\n",
              " 'read': 219,\n",
              " 'carefully': 220,\n",
              " 'valid': 221,\n",
              " 'purchased': 222,\n",
              " '21st': 223,\n",
              " '20th': 224,\n",
              " 'but': 225,\n",
              " 'purchase': 226,\n",
              " 'over': 227,\n",
              " 'installments': 228,\n",
              " 'aug': 229,\n",
              " '2024.': 230,\n",
              " 'why': 231,\n",
              " 'lifetime': 232,\n",
              " 'provided': 233,\n",
              " 'because': 234,\n",
              " 'low': 235,\n",
              " 'reach': 236,\n",
              " 'out': 237,\n",
              " 'doubt': 238,\n",
              " 'fill': 239,\n",
              " 'form': 240,\n",
              " 'team': 241,\n",
              " '1': 242,\n",
              " 'clearance': 243,\n",
              " 'still': 244,\n",
              " 'ask': 245,\n",
              " 'week': 246,\n",
              " 'doubts': 247,\n",
              " 'just': 248,\n",
              " 'select': 249,\n",
              " 'gmai.com': 250,\n",
              " 'certificate': 251,\n",
              " 'placement': 252,\n",
              " 'assistance': 253,\n",
              " 'criteria': 254,\n",
              " 'there': 255,\n",
              " 'criterias': 256,\n",
              " 'attempt': 257,\n",
              " 'assessments': 258,\n",
              " 'joining': 259,\n",
              " 'earlier': 260,\n",
              " 'current': 261,\n",
              " 'that': 262,\n",
              " 'comes': 263,\n",
              " 'under': 264,\n",
              " 'clarify': 265,\n",
              " 'does': 266,\n",
              " 'mean': 267,\n",
              " 'guarantee': 268,\n",
              " 'dont': 269,\n",
              " 'any': 270,\n",
              " 'jobs': 271,\n",
              " 'matter': 272,\n",
              " 'interview': 273,\n",
              " 'calls': 274,\n",
              " 'planning': 275,\n",
              " 'placements': 276,\n",
              " 'afraid': 277,\n",
              " 'disappointed': 278,\n",
              " 'portfolio': 279,\n",
              " 'building': 280,\n",
              " 'soft': 281,\n",
              " 'skill': 282,\n",
              " 'industry': 283,\n",
              " 'mentors': 284,\n",
              " 'discussion': 285,\n",
              " 'job': 286,\n",
              " 'hunting': 287,\n",
              " 'strategies': 288}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = document.split('\\n')"
      ],
      "metadata": {
        "id": "4FDir0iyHplG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "  numerical_sentece= []\n",
        "\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentece.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentece.append(vocab['<unk>'])\n",
        "\n",
        "  return numerical_sentece"
      ],
      "metadata": {
        "id": "dIFjuvWWJMGr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numerical_sentence=[]\n",
        "\n",
        "for sentence in input_sentences:\n",
        "  input_numerical_sentence.append(text_to_indices(word_tokenize(sentence.lower()), vocab))"
      ],
      "metadata": {
        "id": "KIZ4Q0z4IWqs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence = []\n",
        "\n",
        "for sentence in input_numerical_sentence:\n",
        "  for i in range(1, len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])"
      ],
      "metadata": {
        "id": "WpMOt35SJKwH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_list =[]\n",
        "\n",
        "for sequence in training_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ADixZbpL-1Q",
        "outputId": "ecafdc36-f5e2-4eae-9b4d-646d4efbdf90"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence =[]\n",
        "for sequence in training_sequence:\n",
        "\n",
        "  padded_training_sequence.append([0]*(max(len_list) - len(sequence))+sequence)"
      ],
      "metadata": {
        "id": "InXUbEKeN2L8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_training_sequence[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBGtvsGFOkua",
        "outputId": "488a238a-0e4d-428d-9f21-d2d480db79ed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype = torch.long)"
      ],
      "metadata": {
        "id": "FmXzLfLQP5NB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqS2PusbQHTL",
        "outputId": "61a0574b-a02c-4329-d00c-78feb493ac34"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        [  0,   0,   0,  ...,   0,   4,   5],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287],\n",
              "        [  0,   0,   0,  ..., 286, 287, 288]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:,-1]"
      ],
      "metadata": {
        "id": "GlVgn1cxQIOo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLAg7psJQZym",
        "outputId": "27b84802-a395-4948-ba24-685de30ac585"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
              "        [  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   0,   0,   4],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   0, 285, 176],\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBEbVfVBQcH9",
        "outputId": "117ffe71-19dd-4610-d6ff-cab3cf24f4e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   3,   5,   2,   6,   7,   8,   9,  10,  11,   3,  12,  13,  14,\n",
              "         15,   6,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  18,  26,\n",
              "         27,  28,  29,  30,   5,   2,  31,  32,  27,   2,   6,  33,  31,  32,\n",
              "         27,   2,   6,   5,  34,  35,  30,  36,   2,  31,   6,   7,  37,  38,\n",
              "         39,  34,  40,  28,  41,  12,  42,  30,  15,   5,   2,  43,  27,   2,\n",
              "         11,   3,  33,  45,  46,  47,   2,  48,  49,  50,  52,  53,   8,   9,\n",
              "         10,  54,   8,   9,  10,   8,  57,  58,  60,  59,  64,  65,  66,   2,\n",
              "         67,  43,  68,  69,  70,  50,  71,  72,  58,  73,  74,  46,  17,  75,\n",
              "         27,  76,   3,  33,  78,  74,  73,  72,  58,  79,  80,  81,  17,  75,\n",
              "         27,  76,   3,  82,  83,  84,  30,  85,  86,  87,  17,  88,  89,  33,\n",
              "         45,  86,  90,  17,  91,  27,   2,  89,  33,  93,  94,  95,  80,  96,\n",
              "         78,  36,  97,  85,  22,  87,  17,  89,  22,  65,  98,  99,  73, 100,\n",
              "          2,  91,  30,  65,  86, 101,   2, 102, 103,  33,  76, 105, 106,  24,\n",
              "        107, 108, 109, 108, 110, 111,  27,   2,   6,  69,  70,  50, 112,  33,\n",
              "        113,  30,   5,   2, 110,  32,  27,  93,   2,  88,  95,  33,  78,  93,\n",
              "          2,  95, 115, 116, 117,  30,   5,   2, 118, 119, 109,   2, 120, 121,\n",
              "          2,  95,  33,  45,  86,  46, 124,   1,   2, 125, 102,  33,  45,  90,\n",
              "         17, 126, 127,  94, 128, 129, 130, 131,  89, 132,  22, 133,  17, 131,\n",
              "        134,  30,  86, 135,  76,   6,  85,  86, 136, 127,  17, 137, 138,  33,\n",
              "         78, 139,  30, 136, 140,  78,  65,  86, 141,   2,   3, 142,   2, 143,\n",
              "         33,  78,  22,  65, 141,   2,   3, 144,  30,  86, 145, 142,   2, 143,\n",
              "         78,  45,  86,  46, 146,  24, 107,  93,   2, 147, 148,  33,  78, 132,\n",
              "         22,  25,   2, 149,  22,  45,  46, 146,  24, 107,  93,   2, 147, 150,\n",
              "        142, 151, 152,  30, 135,  86,  23,  24, 153,   2, 154,  33, 155,  82,\n",
              "        156,  23,  24, 153,   2, 154,  30,  44,  45, 157,  22, 158,   2, 159,\n",
              "         78,  22,  23,  24, 160, 161,   2, 154, 162,  30,  44, 135,  63,  64,\n",
              "        142,   2,   3,  33,  30,  65,  44, 163,  22,  33,  65, 126, 164, 165,\n",
              "        166, 167, 168, 170, 171, 135,  44,  23,  24,  25,  94,  26,  33, 151,\n",
              "        172, 173, 174, 175,  33,  23,  24,  25,  93, 151,  18,  26, 176,  94,\n",
              "        175,  30,  68,   5,   2, 177,   8,  94, 175,  69,  70,  50, 178,  44,\n",
              "        179,   2, 180, 181,  27,  28,  41,  93, 165, 132,  33,  77,  78,   2,\n",
              "          3,  16,  17,  18,  19,  20,  30,   5,   2, 183,  27,  18,  19,  33,\n",
              "        184,  85,  86, 179, 176, 185, 186,  78, 187, 135,  86,  23,  24, 179,\n",
              "        188, 176, 189, 190, 174, 185, 190, 191,   2, 183, 192,   5, 193, 194,\n",
              "        127,   2, 195,  22,  25,   2, 149,  30,  36, 196,  22,  65, 141, 144,\n",
              "         22, 155,  82, 156,  23,  24, 197,   8,  17, 108,  24, 198,  30,  85,\n",
              "         86, 155,  82, 156, 199,   2,   6, 200, 201,   2, 149,  30,   4,   5,\n",
              "          2, 202, 203,  33,  90,  17,  34, 194, 202, 192, 127,   2, 195,  22,\n",
              "         23, 204,   2, 149,  30, 136, 205, 206, 207,  73,  86, 136,  81, 146,\n",
              "         24,  25,   2, 149, 176,   2, 175,  78,   4, 208,  86, 135,  33,  23,\n",
              "         24, 163, 164, 109, 209,  17, 126, 165, 166, 167, 168, 211, 212, 214,\n",
              "         65,  86, 215,   2, 131, 216, 176,   2, 175,  33, 217,   5, 218,  78,\n",
              "         36, 219, 220,  30,  22,  65, 100,   2, 216, 213, 151,  19,   5, 221,\n",
              "         30, 184,  22,  23, 222,  19, 176, 223, 186,  78,  22,  45,  46, 146,\n",
              "         24, 100,  93,   2, 147, 131,  95, 142,   2, 192,  27, 223, 186,  24,\n",
              "        224, 191, 225, 200, 223, 190,  22,  45,  23,  24, 226,   2,  19, 188,\n",
              "         30, 132,   2,   6,   5, 227,  73,  22,  23, 131, 164,  28,  41,  12,\n",
              "        174,  34, 228,  27,  28,  38,  15,  22,  45,  46, 146,  24, 100,   2,\n",
              "        131,  95, 213, 229,   0,  30, 232, 183,   5,  81, 233,  33,  27,   2,\n",
              "        235,   6,   7,  30,  65,  86, 236, 237, 142,  63,  27,  17, 238, 200,\n",
              "          2,  89,  33,  45,  23,  24, 239,  17, 105, 240, 233, 142, 151, 152,\n",
              "         73,  94, 241,  45, 163,  22,   8,  17, 242, 176, 242, 238, 243,  89,\n",
              "         86, 141,   2,   3, 140,  78,  65,  86, 244, 245, 147, 246, 247,  33,\n",
              "         78, 248, 249, 147, 246, 238, 142,   2, 238, 243, 105, 240,  30, 136,\n",
              "        205, 206, 207,  73,  86, 136,  81, 146,  24,  25,   2, 149, 176,   2,\n",
              "        175,  78,   4, 208,  86, 135,  33,  23,  24, 163, 164, 109, 209,  17,\n",
              "        126, 165, 166, 167, 250,  73, 252, 253, 170, 212,   5,   2, 254,  24,\n",
              "         90,   2, 251,  33,  80, 116, 256,  50,  23,  24, 179,   2, 180,   7,\n",
              "         27,  28,  41,  23,  24, 257,  93,   2,   6, 258,  30, 136, 259, 140,\n",
              "         30, 123,  65,  86, 179, 149,  27,   2, 260,  35,  33,  45,  90,  17,\n",
              "        177,  24, 179,   7,  27, 260,  35, 142, 151, 152, 132,  22, 179,   8,\n",
              "          2, 261, 108,  30,  23, 219, 262, 252, 253,   5,  17,  75,  27,  76,\n",
              "          3,  30,   4, 263, 264, 252, 253,  33,   5,  24, 265, 262, 252, 253,\n",
              "        266,  81, 267, 252, 268,  30,  36,  44, 269, 268,  22, 270, 271, 174,\n",
              "          8, 262, 272,  97, 273, 274,  30,  36,  85,  22,  80, 275,  24, 141,\n",
              "         76,   6, 248,   8, 276,  78,  86, 136, 277,  22,  45,  46, 278,  30,\n",
              "         68,   5,   4, 263, 264, 252, 253, 280,  95, 282,  95, 158, 283, 284,\n",
              "        176, 286, 287, 288])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "9QtBqHVcQeMb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X, y)"
      ],
      "metadata": {
        "id": "4TPxGBubRRTX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "y4yJPTmtRXsc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input, output in dataloader:\n",
        "  print(input, output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh3o-jE4R9N2",
        "outputId": "ae4aac50-abb9-4108-ae60-d39f01b681c0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0,   0,   0,  ..., 231, 232, 183],\n",
            "        [  0,   0,   0,  ...,   6,   5, 227],\n",
            "        [  0,   0,   0,  ...,   2, 260,  35],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 165, 166, 167],\n",
            "        [  0,   0,   0,  ...,  22,  65,  66],\n",
            "        [  0,   0,   0,  ...,  45,  72,  58]]) tensor([  5,  73,  33, 168,   2, 163, 269,  17, 105,  65,   3,  33, 142, 213,\n",
            "        156,   6,  65,  17,  45, 155, 119,  46,   5,  95,  33, 141,  30,  33,\n",
            "        174, 168,   2,  73])\n",
            "tensor([[  0,   0,   0,  ...,   0,  22,  23],\n",
            "        [  0,   0,   0,  ..., 131,  89, 132],\n",
            "        [  0,   0,   0,  ...,   0,   0,  85],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 155,  82, 156],\n",
            "        [  0,   0,   0,  ...,  90,  17,  34],\n",
            "        [  0,   0,   0,  ...,  65, 100,   2]]) tensor([ 24,  22,  86, 135,  65, 243,  85, 167, 179,   3,  91, 149,  78,  65,\n",
            "         86,  17,  30, 220, 180,  30,  78,  45,  65, 188, 126,  26,  65, 226,\n",
            "          6,  23, 194, 216])\n",
            "tensor([[  0,   0,   0,  ...,   3,  82,  83],\n",
            "        [  0,   0,   0,  ...,   2,  11,   3],\n",
            "        [  0,   0,   0,  ..., 200, 223, 190],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 155,  82, 156],\n",
            "        [  0,   0,   0,  ...,  78, 132,  22],\n",
            "        [  0,   0,   0,  ...,  17, 137, 138]]) tensor([ 84,  33,  22, 183,  11, 126, 154, 172, 152,   2, 165, 228, 233,  22,\n",
            "          2,  23, 131,   5, 147,  28,  28,  95,  27,  73,  15,   3, 266,  37,\n",
            "         45,  23,  25,  33])\n",
            "tensor([[  0,   0,   0,  ...,  86, 136,  81],\n",
            "        [  0,   0,   0,  ...,   0,   0,  92],\n",
            "        [  0,   0,   0,  ...,  67,  43,  68],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  27, 223, 186],\n",
            "        [  0,   0,   0,  ..., 197,   8,  17],\n",
            "        [  0,   0,   0,  ..., 149, 176,   2]]) tensor([146,  78,  69,  30,  44,   5,  94, 142,  97,  10,   3, 149,  33, 227,\n",
            "         27, 218,  65,  94,  28,   5,   2,  81,   5,  46,  23,  11, 270,   7,\n",
            "        173,  24, 108, 175])\n",
            "tensor([[  0,   0,   0,  ...,  22,  45,  46],\n",
            "        [  0,   0,   0,  ..., 176,   2, 175],\n",
            "        [  0,   0,   0,  ...,   2, 180, 181],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0,   4],\n",
            "        [  0,   0,   0,  ...,  22,  23,  24],\n",
            "        [  0,   0,   0,  ...,   2, 149,  30]]) tensor([146,  33,  27, 162, 280,  44, 166,   8,  47,  24,  72,  23,  22,  15,\n",
            "         68,  78,  24,  16,  24,  18,  90,  24, 219,  43,  93,   2, 284, 274,\n",
            "         22,   5, 160,   4])\n",
            "tensor([[  0,   0,   0,  ...,  27,  76,   3],\n",
            "        [  0,   0,   0,  ...,   2,  95, 115],\n",
            "        [  0,   0,   0,  ...,   0,   4,   5],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   5,  24, 265],\n",
            "        [  0,   0,   0,  ...,  24,  25,  93],\n",
            "        [  0,   0,   0,  ...,  17,  18,  19]]) tensor([ 33, 116,   2, 149,   2,  27,  15,  19, 131,   2, 131,  24, 147,  78,\n",
            "         33,  85,  86,  30,  86,  50,  89, 175, 109, 107,  86,  71,   6, 141,\n",
            "         24, 262, 151,  20])\n",
            "tensor([[  0,   0,   0,  ..., 158,   2, 159],\n",
            "        [  0,   0,   0,  ...,  34, 228,  27],\n",
            "        [  0,   0,   0,  ..., 253, 266,  81],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 270, 271, 174],\n",
            "        [  0,   0,   0,  ...,   0,  92,  78],\n",
            "        [  0,   0,   0,  ..., 252, 268,  30]]) tensor([ 78,  28, 267, 149,   2,  81,  42,  90, 204, 188,  45,  48,  34, 150,\n",
            "         23,  23,  33, 197, 152, 190,   6,  22,  23, 223,  73, 141,  86, 112,\n",
            "          2,   8, 132,  36])\n",
            "tensor([[  0,   0,   0,  ...,  81,  17,  75],\n",
            "        [  0,   0,   0,  ...,   2,   3, 144],\n",
            "        [  0,   0,   0,  ...,  86, 101,   2],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  22,  45,  46],\n",
            "        [  0,   0,   0,  ...,  24, 224, 191],\n",
            "        [  0,   0,   0,  ...,   0,  55,   8]]) tensor([ 27,  30, 102,  98,  78, 238, 140,   5,  31,  23,  27,  27,   2, 136,\n",
            "        142, 117, 179,  78,   5, 195,   2,  30, 179,  22,  30, 132,   2, 241,\n",
            "         24, 146, 225,   9])\n",
            "tensor([[  0,   0,   0,  ...,  46, 146,  24],\n",
            "        [  0,   0,   0,  ..., 244, 245, 147],\n",
            "        [  0,   0,   0,  ...,  76,   6, 248],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 173, 174, 175],\n",
            "        [  0,   0,   0,  ...,  27,   2,   6],\n",
            "        [  0,   0,   0,  ..., 245, 147, 246]]) tensor([100, 246,   8,  85, 260,  17,  86, 146, 184, 258, 242, 200, 181,  30,\n",
            "          2, 149,  33, 136,  22, 229, 149,  22,  94, 131,  34, 136,  30, 100,\n",
            "         19,  33,  69, 247])\n",
            "tensor([[  0,   0,   0,  ..., 132,  22, 179],\n",
            "        [  0,   0,   0,  ..., 232, 183,   5],\n",
            "        [  0,   0,   0,  ...,  70,  50, 112],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  92,  78, 132],\n",
            "        [  0,   0,   0,  ...,  34, 194, 202],\n",
            "        [  0,   0,   0,  ...,  45,  46,  47]]) tensor([  8,  81,  33, 151,   2, 100, 152,  45, 211,   2,   8, 103, 153,  93,\n",
            "         31, 132,   2, 195,  30, 151,  38,  85,  87,   2, 276, 163,  90,  24,\n",
            "         93,  22, 192,   2])\n",
            "tensor([[  0,   0,   0,  ..., 217,   5, 218],\n",
            "        [  0,   0,   0,  ...,   0, 185, 191],\n",
            "        [  0,   0,   0,  ..., 175,  78,   4],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0,  76],\n",
            "        [  0,   0,   0,  ...,  78,  22,  45],\n",
            "        [  0,   0,   0,  ...,   7,  27,  28]]) tensor([ 78,   2, 208,  22,   2,   6, 275,  30,  33,  24, 174, 186, 157,   8,\n",
            "         32,  33,  89,   2,   2,  97,  30,   2,  95, 165, 179,   2,  21,   2,\n",
            "          2, 217,  46,  41])\n",
            "tensor([[  0,   0,   0,  ...,  95, 142,   2],\n",
            "        [  0,   0,   0,  ..., 176, 242, 238],\n",
            "        [  0,   0,   0,  ...,   0, 231, 232],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,  22, 155],\n",
            "        [  0,   0,   0,  ...,  95,  80,  96],\n",
            "        [  0,   0,   0,  ..., 174,   8, 262]]) tensor([192, 243, 183, 224, 166, 185, 142,  76, 110,  30,  33,  33,   2,  30,\n",
            "        213,  99,   2, 240, 252,  27, 167,  50,  76,  30, 123,  94,  86,  19,\n",
            "         30,  82,  78, 272])\n",
            "tensor([[  0,   0,   0,  ...,   0, 210, 211],\n",
            "        [  0,   0,   0,  ...,   0,   0,  51],\n",
            "        [  0,   0,   0,  ...,  18,  26,  27],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 155,  82, 156],\n",
            "        [  0,   0,   0,  ...,   7,  27, 260],\n",
            "        [  0,   0,   0,  ...,  65,  98,  99]]) tensor([212,  53,  28, 174,   5,  79, 137,   2, 118, 190,   8,  45,  52, 105,\n",
            "        248,  90,  34,  65,   4,  22, 111,  78,  86,  76, 176,  57,  12,  45,\n",
            "        209, 199,  35,  73])\n",
            "tensor([[  0,   0,   0,  ...,   0,   0,  61],\n",
            "        [  0,   0,   0,  ...,   0,  22,  23],\n",
            "        [  0,   0,   0,  ...,   8,  17, 108],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  20,  21,  22],\n",
            "        [  0,   0,   0,  ..., 144,  22, 155],\n",
            "        [  0,   0,   0,  ...,   0,   0,  76]]) tensor([ 59,  24,  24, 194, 147, 142, 185,   2,   2,  35,  73, 144, 254, 176,\n",
            "        156, 115,  25,  67, 128, 259,  17,  18, 240,  24,  63, 287,  86,  45,\n",
            "         50,  23,  82,   5])\n",
            "tensor([[  0,   0,   0,  ...,   0,   4,   5],\n",
            "        [  0,   0,   0,  ..., 110, 111,  27],\n",
            "        [  0,   0,   0,  ...,   2, 131, 216],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  93,   2, 147],\n",
            "        [  0,   0,   0,  ...,  23,  24, 160],\n",
            "        [  0,   0,   0,  ...,  33, 184,  85]]) tensor([  2,   2, 176, 189, 223,   5, 140, 170, 101,  76,  81, 109,  72,  60,\n",
            "         27,  88,  24,  10, 237,  26, 129,  30,  17,  43,   2, 223, 110,  81,\n",
            "         18, 148, 161,  86])\n",
            "tensor([[  0,   0,   0,  ...,   2,   6,  69],\n",
            "        [  0,   0,   0,  ...,  85,  86, 155],\n",
            "        [  0,   0,   0,  ...,  78, 187, 135],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0,  92],\n",
            "        [  0,   0,   0,  ...,  85,  22,  87],\n",
            "        [  0,   0,   0,  ...,   3, 142,   2]]) tensor([ 70,  82,  86, 127,  89, 121,   3,  76,   7,   2,  22,  82,  32, 113,\n",
            "         27,  33, 131,   6,  24, 127, 271,  95, 176,  22,   4,  44,  86, 249,\n",
            "         41,  78,  17, 143])\n",
            "tensor([[  0,   0,   0,  ...,   0,   0,  22],\n",
            "        [  0,   0,   0,  ...,  81, 146,  24],\n",
            "        [  0,   0,   0,  ...,   0,  85,  86],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  11,   3,  12],\n",
            "        [  0,   0,   0,  ...,  17, 242, 176],\n",
            "        [  0,   0,   0,  ..., 252, 253, 170]]) tensor([155,  25, 141,  41,  33, 175,  93,  46,  86, 159,  19, 256,  24,  86,\n",
            "        252,   2, 282, 219, 164,  86, 154, 200, 132,  27,   4, 252,  27, 165,\n",
            "         23,  13, 242, 212])\n",
            "tensor([[  0,   0,   0,  ...,   2, 149,  22],\n",
            "        [  0,   0,   0,  ...,   0,   0,  85],\n",
            "        [  0,   0,   0,  ...,  23,  24, 153],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 164,  28,  41],\n",
            "        [  0,   0,   0,  ..., 146,  24,  25],\n",
            "        [  0,   0,   0,  ...,  94, 175,  69]]) tensor([ 45,  86,   2,  86, 288, 222, 176, 142, 191,  25, 215, 142, 108, 239,\n",
            "          8,  24, 263, 135,  22,  22, 158, 232, 177, 149, 133,   5,   2, 156,\n",
            "          9,  12,   2,  70])\n",
            "tensor([[  0,   0,   0,  ..., 140,  78,  65],\n",
            "        [  0,   0,   0,  ...,   4,   5,   2],\n",
            "        [  0,   0,   0,  ..., 146,  24, 107],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0, 139],\n",
            "        [  0,   0,   0,  ...,  45,  86,  46],\n",
            "        [  0,   0,   0,  ...,   2,  31,  32]]) tensor([ 86,   6,  93,   5, 163,   3,   6, 143, 221, 140,  27,  86, 278, 264,\n",
            "         25, 264, 268,  24, 134, 190, 151,   6,  66, 174, 202,   5,  22,   3,\n",
            "         30,  78, 124,  27])\n",
            "tensor([[  0,   0,   0,  ...,  37,  38,  39],\n",
            "        [  0,   0,   0,  ...,  24,  25,  94],\n",
            "        [  0,   0,   0,  ..., 264, 252, 253],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,  22,  45],\n",
            "        [  0,   0,   0,  ..., 151,  18,  26],\n",
            "        [  0,   0,   0,  ..., 195,  22,  25]]) tensor([ 34,  26,  33, 216, 192, 106,   2,   2,  23, 166, 141, 136, 233,   3,\n",
            "        244,  36, 214,  68,  14, 203, 107,  44,  30, 252,  31,  18, 107, 153,\n",
            "        136,  90, 176,   2])\n",
            "tensor([[  0,   0,   0,  ...,   2,   6,  16],\n",
            "        [  0,   0,   0,  ..., 124,   1,   2],\n",
            "        [  0,   0,   0,  ..., 129, 130, 131],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0, 182],\n",
            "        [  0,   0,   0,  ...,   5,  81, 233],\n",
            "        [  0,   0,   0,  ...,  93,  94,  95]]) tensor([ 17, 125,  89, 205,  30, 146,  22, 253, 268,  73,  65, 251,  91,  78,\n",
            "          2,  93,  24,  89,  24,  89, 200,  88,  23,  29,   2,   5, 130,  33,\n",
            "         22,  77,  33,  80])\n",
            "tensor([[  0,   0,   0,  ...,  86, 135,  76],\n",
            "        [  0,   0,   0,  ...,  24, 179, 188],\n",
            "        [  0,   0,   0,  ...,  23,  24, 179],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   4,   5],\n",
            "        [  0,   0,   0,  ...,   0,  65,  44],\n",
            "        [  0,   0,   0,  ...,  22,  23,  24]]) tensor([  6, 176,   2, 147,  17,  24,  30,  25,  80,   2,  41, 207,  46, 126,\n",
            "        206, 235,  17,  25,  80,   5,  23, 135,   7,  33,  17,  17, 177,  44,\n",
            "         50,   2, 179, 257])\n",
            "tensor([[  0,   0,   0,  ...,   0,  95, 158],\n",
            "        [  0,   0,   0,  ...,  86, 136, 205],\n",
            "        [  0,   0,   0,  ...,  85,  86,  87],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   2,  31,  32],\n",
            "        [  0,   0,   0,  ...,  75,  27,  76],\n",
            "        [  0,   0,   0,  ...,  21,  65,  86]]) tensor([283, 206,  17,  38, 109,  22, 108,  30,  24,  95,  35, 246,  36,  93,\n",
            "        250, 207,  33,  64,  85, 238,  75, 164,  30,   7,   7,  96,  22,   2,\n",
            "         22,  27,   3, 236])\n",
            "tensor([[  0,   0,   0,  ..., 175,  78,   4],\n",
            "        [  0,   0,   0,  ..., 126, 165, 166],\n",
            "        [  0,   0,   0,  ...,   0,  92,  78],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  10,  11,   3],\n",
            "        [  0,   0,   0,  ...,   0,  92,  78],\n",
            "        [  0,   0,   0,  ...,  56,   8,  57]]) tensor([208, 167, 139,  30, 253, 165, 260, 142,  93,  22, 245, 186, 202, 116,\n",
            "        252,  28, 196,  45,  24, 164,  33,   9, 261, 136,  33,  46,  74,  69,\n",
            "         17,  12, 248,  58])\n",
            "tensor([[  0,   0,   0,  ...,   0,   0, 169],\n",
            "        [  0,   0,   0,  ...,  38,  15,  22],\n",
            "        [  0,   0,   0,  ..., 142, 151, 152],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  17,  75,  27],\n",
            "        [  0,   0,   0,  ...,  17, 108,  24],\n",
            "        [  0,   0,   0,  ..., 238, 142,   2]]) tensor([170,  45,  73,  46, 102, 138, 127,   2,   2,  78, 144, 109,  39,   4,\n",
            "        253, 186,  17,  36,  68,  49, 265, 252,  78,  33,   2,  50,  75, 171,\n",
            "         45,  76, 198, 238])\n",
            "tensor([[  0,   0,   0,  ...,  24, 153,   2],\n",
            "        [  0,   0,  76,  ...,  24, 226,   2],\n",
            "        [  0,   0,   0,  ..., 176,   2, 175],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 242, 176, 242],\n",
            "        [  0,   0,   0,  ..., 100,   2, 131],\n",
            "        [  0,   0,   0,  ...,  23,  24, 153]]) tensor([154,  19,  78,  24, 136, 286, 193,  63,  65,  95, 151,   3,   6, 191,\n",
            "         23,  17,  22,  18, 120, 179,  27,  94,  45,  36, 127, 142, 136,   2,\n",
            "         23, 238,  95,   2])\n",
            "tensor([[  0,   0,   0,  ...,   0,   0,   9],\n",
            "        [  0,   0,   0,  ...,   0,  65,  86],\n",
            "        [  0,   0,   0,  ...,  78,  22,  23],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   5,   2,  31],\n",
            "        [  0,   0,   0,  ..., 100,  93,   2],\n",
            "        [  0,   0,   0,  ...,   0, 234,  27]]) tensor([ 54, 135,  24, 176,   1,   2,  17, 187,  86,   8,  44,  78,   2,  40,\n",
            "         30,  23,   2, 135,   5, 126, 253,  30,  83, 175,  23,  10,   8,  65,\n",
            "          2,  32, 147,   2])\n",
            "tensor([[  0,   0,   0,  ..., 262, 272,  97],\n",
            "        [  0,   0,   0,  ...,   8,  17, 242],\n",
            "        [  0,   0,   0,  ...,  78,   2,   3],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   2,   6, 258],\n",
            "        [  0,   0,   0,  ...,  43,  68,  69],\n",
            "        [  0,   0,   0,  ..., 219, 220,  30]]) tensor([273, 176,  16, 209, 277, 132,  65,   2, 184,  24, 145, 164,  27,  85,\n",
            "         74,   2, 163,   2, 262,  30,  30,  30,  58,   6,  36,  17, 175, 155,\n",
            "        263,  30,  70,  22])\n",
            "tensor([[  0,   0,   0,  ...,  74,  46,  17],\n",
            "        [  0,   0,   0,  ..., 132,  22,  25],\n",
            "        [  0,   0,   0,  ...,   0,  45,  72],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  94,  26,  33],\n",
            "        [  0,   0,   0,  ...,   5,   2,  43],\n",
            "        [  0,   0,   0,  ...,  69,  70,  50]]) tensor([ 75,   2,  58,  19,  95,   3,  33,  80, 135, 262, 253,  46, 180,  93,\n",
            "         45,  86,  94,   2, 179,  27, 158, 131, 135,  86, 105,  87, 201,  33,\n",
            "        100, 151,  27, 178])\n",
            "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,  45,  44, 135,  63],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  77,  78,  74,  73,\n",
            "          72,  58,  79,  80,  81],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 182,  77,  78,   2,\n",
            "           3,  16,  17,  18,  19],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0, 225, 132,   2,   6,   5, 227,  73,  22,  23, 131, 164,  28,  41,\n",
            "          12, 174,  34, 228,  27,  28,  38,  15,  22,  45,  46, 146,  24, 100,\n",
            "           2, 131,  95, 213, 229],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,  22],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76,\n",
            "           5,  24, 265, 262, 252, 253, 266,  81, 267, 252, 268,  30,  36,  44,\n",
            "         269, 268,  22, 270, 271, 174,   8, 262, 272,  97, 273, 274,  30,  36,\n",
            "          85,  22,  80, 275,  24, 141,  76,   6, 248,   8, 276,  78,  86, 136,\n",
            "         277,  22,  45,  46, 278],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,  76, 217,   5, 218,  78,  36, 219, 220,  30,  22,  65, 100,   2,\n",
            "         216, 213, 151,  19,   5, 221,  30, 184,  22,  23, 222,  19, 176, 223,\n",
            "         186,  78,  22,  45,  46],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   4,   5,   2],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,  86, 136],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22,\n",
            "          45,  90,  17, 177,  24, 179,   7,  27, 260,  35, 142, 151, 152, 132,\n",
            "          22, 179,   8,   2, 261],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,\n",
            "           5,   2,  31,  32,  27],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,  65,  44, 179],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22,  45,\n",
            "          90,  17, 177,  24, 179,   7,  27, 260,  35, 142, 151, 152, 132,  22,\n",
            "         179,   8,   2, 261, 108],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0, 213, 214,  65,  86, 215,\n",
            "           2, 131, 216, 176,   2]]) tensor([ 64,  17,  20,   0,  65,  30, 146, 183, 205, 108,   2,   2,  30, 175])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, X):\n",
        "    embedded = self.embedding(X)\n",
        "    intermediate_hidden_state, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "M9lifIqISLPH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(len(vocab))"
      ],
      "metadata": {
        "id": "zf4aekosa9_F"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "vygDPXxWbKgm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeS0lgFObZDF",
        "outputId": "056e2624-0940-4266-9189-f150d2e96019"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(289, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=289, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "c_ETmfzZbbTC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_loss=0\n",
        "  for batch_X, batch_y in dataloader:\n",
        "    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(batch_X)\n",
        "\n",
        "    loss = criterion(output, batch_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f'epochs:{epoch+1}, loss:{total_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNjsNsYkbxnj",
        "outputId": "ac99214e-876b-47e3-9fea-b247d4b9f773"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs:1, loss:165.5131\n",
            "epochs:2, loss:146.8085\n",
            "epochs:3, loss:135.4972\n",
            "epochs:4, loss:123.0285\n",
            "epochs:5, loss:111.7917\n",
            "epochs:6, loss:100.4989\n",
            "epochs:7, loss:89.9657\n",
            "epochs:8, loss:80.4730\n",
            "epochs:9, loss:72.2896\n",
            "epochs:10, loss:64.1598\n",
            "epochs:11, loss:56.8351\n",
            "epochs:12, loss:50.2019\n",
            "epochs:13, loss:44.6945\n",
            "epochs:14, loss:39.5783\n",
            "epochs:15, loss:35.0290\n",
            "epochs:16, loss:30.8734\n",
            "epochs:17, loss:27.2934\n",
            "epochs:18, loss:24.6174\n",
            "epochs:19, loss:21.6430\n",
            "epochs:20, loss:19.4569\n",
            "epochs:21, loss:17.5379\n",
            "epochs:22, loss:15.8837\n",
            "epochs:23, loss:14.4822\n",
            "epochs:24, loss:13.0348\n",
            "epochs:25, loss:11.9836\n",
            "epochs:26, loss:11.2173\n",
            "epochs:27, loss:10.2347\n",
            "epochs:28, loss:9.6087\n",
            "epochs:29, loss:9.1892\n",
            "epochs:30, loss:8.5030\n",
            "epochs:31, loss:8.1088\n",
            "epochs:32, loss:7.6088\n",
            "epochs:33, loss:7.2764\n",
            "epochs:34, loss:6.9677\n",
            "epochs:35, loss:6.7559\n",
            "epochs:36, loss:6.3371\n",
            "epochs:37, loss:6.1202\n",
            "epochs:38, loss:5.9038\n",
            "epochs:39, loss:5.7405\n",
            "epochs:40, loss:5.4664\n",
            "epochs:41, loss:5.4696\n",
            "epochs:42, loss:5.2300\n",
            "epochs:43, loss:5.0936\n",
            "epochs:44, loss:5.0331\n",
            "epochs:45, loss:4.9367\n",
            "epochs:46, loss:4.8475\n",
            "epochs:47, loss:4.7758\n",
            "epochs:48, loss:4.5817\n",
            "epochs:49, loss:4.6955\n",
            "epochs:50, loss:4.4623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, vocab, text):\n",
        "  tokenized_text = word_tokenize(text)\n",
        "\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "  padded_text = torch.tensor([0]*(61-len(numerical_text)) + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "  output = model(padded_text)\n",
        "\n",
        "  value, index = torch.max(output, dim=1)\n",
        "\n",
        "  return text + \" \" + list(vocab.keys())[index]"
      ],
      "metadata": {
        "id": "X_0rDXKSdNnI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model, vocab, 'I am living outside India and I am not able')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SysZcfokhWGk",
        "outputId": "27c7c8a7-9ccc-429e-92bf-c404a5a6da25"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am living outside India and I am not able to'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens=15\n",
        "input_text='I am living outside India and I am not able'\n",
        "for i in range(num_tokens):\n",
        "  output_text = prediction(model, vocab, input_text)\n",
        "  print(output_text)\n",
        "  input_text = output_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjGgvEpVheQm",
        "outputId": "f989c081-2bd9-4a48-fbcb-950c08275f60"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am living outside India and I am not able to\n",
            "I am living outside India and I am not able to make\n",
            "I am living outside India and I am not able to make the\n",
            "I am living outside India and I am not able to make the payment\n",
            "I am living outside India and I am not able to make the payment on\n",
            "I am living outside India and I am not able to make the payment on the\n",
            "I am living outside India and I am not able to make the payment on the website\n",
            "I am living outside India and I am not able to make the payment on the website ,\n",
            "I am living outside India and I am not able to make the payment on the website , what\n",
            "I am living outside India and I am not able to make the payment on the website , what should\n",
            "I am living outside India and I am not able to make the payment on the website , what should i\n",
            "I am living outside India and I am not able to make the payment on the website , what should i do\n",
            "I am living outside India and I am not able to make the payment on the website , what should i do ?\n",
            "I am living outside India and I am not able to make the payment on the website , what should i do ? ?\n",
            "I am living outside India and I am not able to make the payment on the website , what should i do ? ? ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4IF_UsrDh9LB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}